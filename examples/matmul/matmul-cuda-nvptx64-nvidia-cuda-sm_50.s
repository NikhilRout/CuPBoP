//
// Generated by LLVM NVPTX Back-End
//

.version 7.5
.target sm_50
.address_size 64

	// .globl	_Z9matrixMulPfS_S_i
.global .align 1 .b8 blockIdx[1];
.global .align 1 .b8 blockDim[1];
.global .align 1 .b8 threadIdx[1];

.visible .entry _Z9matrixMulPfS_S_i(
	.param .u64 _Z9matrixMulPfS_S_i_param_0,
	.param .u64 _Z9matrixMulPfS_S_i_param_1,
	.param .u64 _Z9matrixMulPfS_S_i_param_2,
	.param .u32 _Z9matrixMulPfS_S_i_param_3
)
{
	.local .align 8 .b8 	__local_depot0[48];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<4>;
	.reg .b32 	%r<34>;
	.reg .f32 	%f<6>;
	.reg .b64 	%rd<22>;

	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r1, [_Z9matrixMulPfS_S_i_param_3];
	ld.param.u64 	%rd3, [_Z9matrixMulPfS_S_i_param_2];
	ld.param.u64 	%rd2, [_Z9matrixMulPfS_S_i_param_1];
	ld.param.u64 	%rd1, [_Z9matrixMulPfS_S_i_param_0];
	cvta.to.global.u64 	%rd4, %rd3;
	cvta.global.u64 	%rd5, %rd4;
	cvta.to.global.u64 	%rd6, %rd2;
	cvta.global.u64 	%rd7, %rd6;
	cvta.to.global.u64 	%rd8, %rd1;
	cvta.global.u64 	%rd9, %rd8;
	st.u64 	[%SP+0], %rd9;
	st.u64 	[%SP+8], %rd7;
	st.u64 	[%SP+16], %rd5;
	st.u32 	[%SP+24], %r1;
	mov.u32 	%r2, %ctaid.y;
	mov.u32 	%r3, %ntid.y;
	mul.lo.s32 	%r4, %r2, %r3;
	mov.u32 	%r5, %tid.y;
	add.s32 	%r6, %r4, %r5;
	st.u32 	[%SP+28], %r6;
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %ntid.x;
	mul.lo.s32 	%r9, %r7, %r8;
	mov.u32 	%r10, %tid.x;
	add.s32 	%r11, %r9, %r10;
	st.u32 	[%SP+32], %r11;
	ld.u32 	%r12, [%SP+28];
	ld.u32 	%r13, [%SP+24];
	setp.ge.s32 	%p1, %r12, %r13;
	@%p1 bra 	LBB0_7;
	bra.uni 	LBB0_1;
LBB0_1:
	ld.u32 	%r14, [%SP+32];
	ld.u32 	%r15, [%SP+24];
	setp.ge.s32 	%p2, %r14, %r15;
	@%p2 bra 	LBB0_7;
	bra.uni 	LBB0_2;
LBB0_2:
	mov.u32 	%r16, 0;
	st.u32 	[%SP+36], %r16;
	st.u32 	[%SP+40], %r16;
	bra.uni 	LBB0_3;
LBB0_3:
	ld.u32 	%r17, [%SP+40];
	ld.u32 	%r18, [%SP+24];
	setp.ge.s32 	%p3, %r17, %r18;
	@%p3 bra 	LBB0_6;
	bra.uni 	LBB0_4;
LBB0_4:
	ld.u64 	%rd14, [%SP+0];
	ld.u32 	%r24, [%SP+28];
	ld.u32 	%r25, [%SP+24];
	mul.lo.s32 	%r26, %r24, %r25;
	ld.u32 	%r27, [%SP+40];
	add.s32 	%r28, %r26, %r27;
	cvt.s64.s32 	%rd15, %r28;
	shl.b64 	%rd16, %rd15, 2;
	add.s64 	%rd17, %rd14, %rd16;
	ld.f32 	%f2, [%rd17];
	ld.u64 	%rd18, [%SP+8];
	mul.lo.s32 	%r29, %r27, %r25;
	ld.u32 	%r30, [%SP+32];
	add.s32 	%r31, %r29, %r30;
	cvt.s64.s32 	%rd19, %r31;
	shl.b64 	%rd20, %rd19, 2;
	add.s64 	%rd21, %rd18, %rd20;
	ld.f32 	%f3, [%rd21];
	ld.f32 	%f4, [%SP+36];
	fma.rn.f32 	%f5, %f2, %f3, %f4;
	st.f32 	[%SP+36], %f5;
	bra.uni 	LBB0_5;
LBB0_5:
	ld.u32 	%r32, [%SP+40];
	add.s32 	%r33, %r32, 1;
	st.u32 	[%SP+40], %r33;
	bra.uni 	LBB0_3;
LBB0_6:
	ld.f32 	%f1, [%SP+36];
	ld.u64 	%rd10, [%SP+16];
	ld.u32 	%r19, [%SP+28];
	ld.u32 	%r20, [%SP+24];
	mul.lo.s32 	%r21, %r19, %r20;
	ld.u32 	%r22, [%SP+32];
	add.s32 	%r23, %r21, %r22;
	cvt.s64.s32 	%rd11, %r23;
	shl.b64 	%rd12, %rd11, 2;
	add.s64 	%rd13, %rd10, %rd12;
	st.f32 	[%rd13], %f1;
	bra.uni 	LBB0_7;
LBB0_7:
	ret;

}
